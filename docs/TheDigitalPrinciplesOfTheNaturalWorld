hello, everyone, i am a Digital Knight in the world, and I am also a university student majoring in electronic information engineering. During my graduate studies, I researched brain imaging. Now, I work as a senior systems architect in a certain prestigious institution. Years of professional experience have allowed me to have the privilege of examining the physical world we live in from an interdisciplinary perspective.
With the development of artificial intelligence, understanding the essence of the world is becoming increasingly important in order to better learn AI technologies. hence, i will attempt to systematically understand the digital essence of the world for everyone.
Different professions and industries have different perspectives on the world. In the eyes of software engineers, everything is an object, and the world is a hierarchical tree structure. Each person is a hash collision in the tree structure with time domain, seeking their optimal position in this world. 
Hardware and image processing engineers, on the other hand, see the world in terms of digits. Each person's body can be stored in a three-dimensional digital matrix on a computer. Even the cognitive decision-making process in our brains can be detected through functional magnetic resonance imaging and stored in a computer as a four-dimensional time series digital matrix. Black and white images are essentially two-dimensional matrices representing brightness values, while color images are digital matrices composed of RGB vector spaces. Our vibrant physical world is actually a world composed of digits, and when overlaid with changes in the time dimension, it becomes a signal. The essence of human brain thinking activity lies in the variation of signals from different regions of neurons. The images presented in our brains are actually a form of digital signal. By detecting and extracting this signal, computer programs can technically decode this image, thus revealing what image your brain was thinking about just now.
Our voice is also a form of digital signal. As a brilliant discovery, I can't help but marvel at the greatness of signal and system science, such as Fourier transforms and convolution. These foundational disciplines are widely applied in the fields of machine learning and artificial intelligence. For example, convolution is used in image segmentation to extract features, essentially acting as a filter. When identifying whether a vehicle in an image is a truck or a car, we filter out signals unrelated to vehicles in the image background using convolution filters, extracting only vehicle-related features, which are then input into a classification network for recognition. Fourier transforms can be used for filtering medical images, such as high-pass and low-pass filtering. High-pass filtering can enhance the edges and details of an image, while low-pass filtering can smooth the image and remove noise. Fourier transforms can also be used for frequency domain analysis, such as detecting periodic structures or specific frequency components in an image, which is very helpful for diagnosing and analyzing specific lesions or structures in medical images. Since the data obtained from imaging our body's structure is essentially a digital signal matrix, in the absence of abnormalities, all soft tissues in the body are uniform, resulting in uniform imaging signals. However, if there is a lesion in a certain soft tissue area, the signal intensity will change. This is why machine learning or artificial intelligence models can be used to segment and identify lesion areas, guiding precise operations by surgical robots and disease diagnosis. It is important to remember that the essence of AI image analysis lies in exploring the features of digital signals.
The perceptron, which is actually the origin of neural networks, is essentially a digital logic circuit. The principle by which neurons in our brain control our limbs is highly consistent with the principles of chips, making the brain equivalent to a CPU. Understanding the essence of this physical world is essential to comprehend the fundamental principles of how the brain generates intelligence. Since this physical world is a digital world where everything is digital, we know that computers use 0 and 1 encoding to store data. But how do neurons in the brain store the data of a person's lifetime? Currently, the disciplines of neural coding and computation are working hard to unravel this mystery. If the foundational disciplines in this direction can make a breakthrough, it may drive the development and application of neuromorphic chips. Because the brain is actually similar to a computer, with the hippocampus storing memory data, the brain's network model can access this data at any time. As the brain's sensor, our eyes transmit various data from the physical world to the visual neurons in the occipital lobe at the back of the brain. These neural network models process these data features, such as whether the animal's ears are pointed or round, and input them into the brain's cognitive decision-making system, allowing you to determine whether it is a dog or a cat. Various deep learning models in artificial intelligence simulate the brain's visual mechanism and have been applied very accurately in fields such as facial recognition and image processing. The precision of recognition even exceeds that of the human brain.
